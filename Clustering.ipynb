{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cluster class for Module 3\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "class Cluster:\n",
    "    \"\"\"\n",
    "    Class for creating and merging clusters of counties\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fips_codes, horiz_pos, vert_pos, population, risk):\n",
    "        \"\"\"\n",
    "        Create a cluster based the models a set of counties' data\n",
    "        \"\"\"\n",
    "        self._fips_codes=[]\n",
    "        self._fips_codes.append(fips_codes) \n",
    "        self._horiz_center = horiz_pos\n",
    "        self._vert_center = vert_pos\n",
    "        self._total_population = population\n",
    "        self._averaged_risk = risk\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        String representation assuming the module is \"alg_cluster\".\n",
    "        \"\"\"\n",
    "        rep = \"alg_cluster.Cluster(\"\n",
    "        rep += str(self._fips_codes) + \", \"\n",
    "        rep += str(self._horiz_center) + \", \"\n",
    "        rep += str(self._vert_center) + \", \"\n",
    "        rep += str(self._total_population) + \", \"\n",
    "        rep += str(self._averaged_risk) + \")\"\n",
    "        return rep\n",
    "\n",
    "\n",
    "    def fips_codes(self):\n",
    "        \"\"\"\n",
    "        Get the cluster's set of FIPS codes\n",
    "        \"\"\"\n",
    "        return self._fips_codes\n",
    "    \n",
    "    def horiz_center(self):\n",
    "        \"\"\"\n",
    "        Get the averged horizontal center of cluster\n",
    "        \"\"\"\n",
    "        return self._horiz_center\n",
    "    \n",
    "    def vert_center(self):\n",
    "        \"\"\"\n",
    "        Get the averaged vertical center of the cluster\n",
    "        \"\"\"\n",
    "        return self._vert_center\n",
    "    \n",
    "    def total_population(self):\n",
    "        \"\"\"\n",
    "        Get the total population for the cluster\n",
    "        \"\"\"\n",
    "        return self._total_population\n",
    "    \n",
    "    def averaged_risk(self):\n",
    "        \"\"\"\n",
    "        Get the averaged risk for the cluster\n",
    "        \"\"\"\n",
    "        return self._averaged_risk\n",
    "   \n",
    "        \n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        Return a copy of a cluster\n",
    "        \"\"\"\n",
    "        copy_cluster = Cluster(list(self._fips_codes), self._horiz_center, self._vert_center,\n",
    "                               self._total_population, self._averaged_risk)\n",
    "        return copy_cluster\n",
    "\n",
    "\n",
    "    def distance(self, other_cluster):\n",
    "        \"\"\"\n",
    "        Compute the Euclidean distance between two clusters\n",
    "        \"\"\"\n",
    "        vert_dist = self._vert_center - other_cluster.vert_center()\n",
    "        horiz_dist = self._horiz_center - other_cluster.horiz_center()\n",
    "        return math.sqrt(vert_dist ** 2 + horiz_dist ** 2)\n",
    "        \n",
    "    def merge_clusters(self, other_cluster):\n",
    "        \"\"\"\n",
    "        Merge one cluster into another\n",
    "        The merge uses the relatively populations of each\n",
    "        cluster in computing a new center and risk\n",
    "        \n",
    "        Note that this method mutates self\n",
    "        \"\"\"\n",
    "        if len(other_cluster.fips_codes()) == 0:\n",
    "            return self\n",
    "        else:\n",
    "            self._fips_codes.append(other_cluster.fips_codes())\n",
    " \n",
    "            # compute weights for averaging\n",
    "            self_weight = float(self._total_population)                        \n",
    "            other_weight = float(other_cluster.total_population())\n",
    "            self._total_population = self._total_population + other_cluster.total_population()\n",
    "            self_weight /= self._total_population\n",
    "            other_weight /= self._total_population\n",
    "                    \n",
    "            # update center and risk using weights\n",
    "            self._vert_center = self_weight * self._vert_center + other_weight * other_cluster.vert_center()\n",
    "            self._horiz_center = self_weight * self._horiz_center + other_weight * other_cluster.horiz_center()\n",
    "            self._averaged_risk = self_weight * self._averaged_risk + other_weight * other_cluster.averaged_risk()\n",
    "            return self\n",
    "\n",
    "    def cluster_error(self, data_table):\n",
    "        \"\"\"\n",
    "        Input: data_table is the original table of cancer data used in creating the cluster.\n",
    "        \n",
    "        Output: The error as the sum of the square of the distance from each county\n",
    "        in the cluster to the cluster center (weighted by its population)\n",
    "        \"\"\"\n",
    "        # Build hash table to accelerate error computation\n",
    "        fips_to_line = {}\n",
    "        for line_idx in range(len(data_table)):\n",
    "            line = data_table[line_idx]\n",
    "            fips_to_line[line[0]] = line_idx\n",
    "        \n",
    "        # compute error as weighted squared distance from counties to cluster center\n",
    "        total_error = 0\n",
    "        counties = self.fips_codes()\n",
    "        for county in counties:\n",
    "            line = data_table[fips_to_line[county]]\n",
    "            singleton_cluster = Cluster(set([line[0]]), line[1], line[2], line[3], line[4])\n",
    "            singleton_distance = self.distance(singleton_cluster)\n",
    "            total_error += (singleton_distance ** 2) * singleton_cluster.total_population()\n",
    "        return total_error\n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIRECTORY = \"http://commondatastorage.googleapis.com/codeskulptor-assets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_3108_URL = DIRECTORY + \"data_clustering/unifiedCancerData_3108.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url=DATA_3108_URL \n",
    "import urllib.request\n",
    "def load_data(url):\n",
    "    with urllib.request.urlopen(url) as url :\n",
    "        s=url.read()\n",
    "        data=s.decode('utf8')\n",
    "        data=data.split('\\r\\n')\n",
    "        data_tokens=[line.split(\", \")for  line in data]\n",
    "        return [[tokens[0], float(tokens[1]), float(tokens[2]), int(tokens[3]), float(tokens[4])] \n",
    "                for tokens in data_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01067', 741.064829551, 454.67645286, 16310, 3.4e-05]\n",
      "['01061', 730.413538241, 465.838757711, 25764, 3.8e-05]\n"
     ]
    }
   ],
   "source": [
    "point1=load_data(url)[1]\n",
    "print(point1)\n",
    "point2=load_data(url)[2]\n",
    "print(point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alg_cluster.Cluster(['01067'], 741.064829551, 454.67645286, 16310, 3.4e-05)\""
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1=Cluster(point1[0],point1[1],point1[2],point1[3],point1[4])\n",
    "c1.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alg_cluster.Cluster(['01061'], 730.413538241, 465.838757711, 25764, 3.8e-05)\""
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2=Cluster(point2[0],point2[1],point2[2],point2[3],point2[4])\n",
    "c2.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.42877364397901"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.distance(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3=c1.merge_clusters(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01067', ['01061']]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1._fips_codes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "slow_closest_pair(cluster_list) - Takes a list of Cluster objects and returns a closest pair where the pair is represented by the tuple (dist, idx1, idx2) with idx1 < idx2 where dist is the distance between the closest pair cluster_list[idx1] and cluster_list[idx2]. This function should implement the brute-force closest pair method described in SlowClosestPair from Homework 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  math\n",
    "def slow_closest_pair(cluster_list):\n",
    "    minimum_point=(math.inf,-1,-1)\n",
    "    for  index1 in range(0,len(cluster_list)):\n",
    "        for index2 in  range(0,len(cluster_list)):\n",
    "            #if cluster_list[index1]._fips_codes!=cluster_list[index2]._fips_codes:\n",
    "            if index1<index2:\n",
    "                \n",
    "                if cluster_list[index1].distance(cluster_list[index2])<minimum_point[0]:\n",
    "                    minimum_point=(cluster_list[index1].distance(cluster_list[index2]),index1,index2)\n",
    "        \n",
    "    return minimum_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_point=(math.inf,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_list=[c1,c2,c3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0, 2)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_closest_pair(cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alg_cluster.Cluster(['01067', ['01061']], 734.5425148361917, 461.5116865478158, 42074, 3.6449398678518803e-05)\""
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alg_cluster.Cluster(['01061'], 730.413538241, 465.838757711, 25764, 3.8e-05)\""
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.980969200296992"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.distance(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alg_cluster.Cluster(['01067', ['01061'], ['01061']], 732.974382624179, 463.1550525292463, 67838, 3.7038297119608485e-05)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.distance(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
